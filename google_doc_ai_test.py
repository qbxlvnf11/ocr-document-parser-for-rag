import os
import io
import sys
import logging
import time
from pathlib import Path
from dotenv import load_dotenv
from google.api_core.client_options import ClientOptions
from google.cloud import documentai_v1 as documentai
from pypdf import PdfReader, PdfWriter

# 1. í™˜ê²½ ë³€ìˆ˜ ë° ë¡œê¹… ì„¤ì •
load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def format_time(seconds: float) -> str:
    ms = seconds * 1000
    if ms < 1000:
        return f"{ms:.2f}ms"
    return f"{seconds:.2f}s"

def process_layout_parser(client, processor_name, pdf_bytes):
    """Document AI API í˜¸ì¶œ ë¡œì§ (Layout Parser v1.5)"""
    raw_document = documentai.RawDocument(content=pdf_bytes, mime_type="application/pdf")

    # RAG ì „ìš© ë ˆì´ì•„ì›ƒ ì„¤ì •
    process_options = documentai.ProcessOptions(
        layout_config=documentai.ProcessOptions.LayoutConfig(
            chunking_config=documentai.ProcessOptions.LayoutConfig.ChunkingConfig(
                chunk_size=1024,
                include_ancestor_headings=True, # ë¬¸ë§¥ ë³´ì¡´ì„ ìœ„í•´ ìƒìœ„ ì œëª© í¬í•¨
            ),
        ),
    )

    request = documentai.ProcessRequest(
        name=processor_name,
        raw_document=raw_document,
        process_options=process_options,
    )

    result = client.process_document(request=request)
    return result.document

def run_pipeline(input_path: str):
    start_total = time.perf_counter()
    
    # 2. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    project_id = os.getenv("GCP_PROJECT_ID")
    location = os.getenv("GCP_LOCATION", "us")
    processor_id = os.getenv("GCP_PROCESSOR_ID")
    
    if not all([project_id, processor_id]):
        logger.error("âŒ .env íŒŒì¼ì— GCP_PROJECT_ID ë˜ëŠ” GCP_PROCESSOR_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # 3. ê²½ë¡œ ì„¤ì •
    pdf_file = Path(input_path)
    if not pdf_file.exists():
        logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_file.absolute()}")
        return

    # ì¶œë ¥ íŒŒì¼ëª…: [íŒŒì¼ëª…]_google_doc_ai_layout_parser.md
    output_file = pdf_file.with_name(f"{pdf_file.stem}_google_doc_ai_layout_parser.md")

    # 4. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    opts = ClientOptions(api_endpoint=f"{location}-documentai.googleapis.com")
    client = documentai.DocumentProcessorServiceClient(client_options=opts)
    
    # ë ˆì´ì•„ì›ƒ íŒŒì„œ v1.5 ê³ ì • ë²„ì „ ì„¤ì •
    processor_version_id = 'pretrained-layout-parser-v1.5-2025-08-25'
    processor_name = f"projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}"

    # 5. PDF ì½ê¸° ë° ì„¤ì •
    reader = PdfReader(str(pdf_file))
    total_pages = len(reader.pages)
    chunk_page_limit = 15  # ì•ˆì „í•œ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŽ˜ì´ì§€ ë¶„í•  ë‹¨ìœ„
    merged_text = ""

    logger.info(f"ðŸš€ ë¶„ì„ ì‹œìž‘: {pdf_file.name} (ì´ {total_pages}p)")
    logger.info(f"ðŸ“‚ ì €ìž¥ ê²½ë¡œ: {output_file.absolute()}")

    # 6. ë©”ì¸ ì²˜ë¦¬ ë£¨í”„
    for start in range(0, total_pages, chunk_page_limit):
        end = min(start + chunk_page_limit, total_pages)
        chunk_start_time = time.perf_counter()
        logger.info(f"ðŸ”„ ì²˜ë¦¬ ì¤‘: {start+1} ~ {end} íŽ˜ì´ì§€ / {total_pages}p")

        # ë©”ëª¨ë¦¬ ë‚´ì—ì„œ PDF ë¶„í• 
        writer = PdfWriter()
        for i in range(start, end):
            writer.add_page(reader.pages[i])
        
        pdf_buffer = io.BytesIO()
        writer.write(pdf_buffer)
        pdf_bytes = pdf_buffer.getvalue()

        try:
            # ë¶„ë¦¬ëœ í•¨ìˆ˜ í˜¸ì¶œ
            document = process_layout_parser(client, processor_name, pdf_bytes)

            if hasattr(document, 'chunked_document'):
                # ê° ì²­í¬ì˜ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìžì—´ë¡œ ê²°í•©
                for chunk_id, chunk in enumerate(document.chunked_document.chunks):
                    logging.info(f"========> Chunk {chunk_id} content <========\n\n{chunk.content}")
                    merged_text += chunk.content + "\n\n"
                    logging.info(f"====================================================\n")
                
                chunk_duration = time.perf_counter() - chunk_start_time
                logger.info(f"   âœ… ì„±ê³µ! ({format_time(chunk_duration)})")
            else:
                logger.warning(f"   âš ï¸ íŽ˜ì´ì§€ {start+1}~{end}: ë°ì´í„°ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            logger.error(f"   âŒ ì—ëŸ¬ ë°œìƒ (íŽ˜ì´ì§€ {start+1}~{end}): {e}")
        
        # API ì¿¼í„° ë³´í˜¸ë¥¼ ìœ„í•œ ëŒ€ê¸°
        time.sleep(0.5)

    # 7. ë‹¨ì¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ìž¥
    if merged_text.strip():
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(merged_text.strip())
        
        total_duration = time.perf_counter() - start_total
        logger.info(f"âœ¨ ëª¨ë“  ìž‘ì—… ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {format_time(total_duration)}")
        logger.info(f"ðŸ“ ê²°ê³¼ í™•ì¸: {output_file.name}")
    else:
        logger.error("âŒ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python layout_parser_merged.py <pdf_path>")
    else:
        run_pipeline(sys.argv[1])